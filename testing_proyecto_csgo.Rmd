---
title: "Testing proyecto csgo"
author: "Sergio y Javi"
date: "2023-01-13"
output: html_document
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install.packages("ggplot2")
library(ggplot2)
library(psych)
library(caret)
library(e1071)
library(stringr)
library(rpart)
```

```{r}
df <- read.csv("/home/javiortig/uni/aprendizaje-automatico/proyecto/csgo_round_snapshots.csv")
```

```{r}
set.seed(1)
df = df[sample(1:nrow(df)), ]
```


```{r}
df_test <- head(df, 50000)
```

```{r}
dim(df_test)
```
```{r}
colnames(df_test)
```

```{r}
head(df_test)
```

```{r}
summary(df_test)
```

```{r}
str(df_test)
```


# Comprobar si existe duplicidad en el dataset

```{r}
any(duplicated(df_test))
```

# Como muestra "TRUE" significa que existen datos duplicados, vamos a quitarlos

```{r}
df_test[duplicated(df_test), ]
```

```{r}
df_test <- unique(df_test)
dim(df_test)
```


```{r}
str(df_test)
```


```{r}
View(df_test)
```

```{r}
# remover "de_" de las casillas de la columna "col_name"
df_test$map <- sub("de_","", df_test$map)

# convertir la primera letra de cada casilla a mayúscula
df_test$map <- str_to_title(df_test$map)

```

```{r}
View(df_test)
```

```{r}
dim(df_test)
```

```{r}
colSums(is.na(df_test))
```
```{r}
ggplot(df_test, aes(x = round_winner)) + geom_bar(aes(fill = round_winner)) +
  stat_count(aes(label = ..count..), geom = "text", vjust = 2.0, color = "black", size = 4.5) +
  ggtitle("Rondas ganadas por cada equipo") +
  xlab("") + 
  ylab("Número de rondas") +
  scale_fill_discrete(name = "Ganador ronda")
```
Viendo esta gráfica, nos damos cuenta que los Terroristas tienen cierta ventaja en general contra los CT. Esto tiene sentido, ya que los propios creadores han publicado estadísticas similares anteriormente, por lo que hemos obtenido una pista más de que los datos creados que tenemos son de calidad.


# Estas son las columnas con todo valor 0:
```{r}
which(colSums(df_test == 0) == nrow(df_test))
```

# Borrar las columnas que tienen todos sus valores "0"
```{r}
df_test <- df_test[, colSums(df_test != 0) > 0]
```

```{r}
dim(df_test)
```
# Hemos conseguido borrar 14 columnas

```{r}
head(df_test)
```
Borramos toas las columnas con valor 0, esto se debe a que en el competitivo del cs_go hay ciertas armas que nunca se usan, por eso no sorprende que siempre sean 0.


---------------------------------------------------
ETIQUETAR Y CODIFICAR TODOS LOS VALORES CATEGÓRICOS
---------------------------------------------------

# La primera línea convierte la columna especificada (en este caso 'map') a un factor.
```{r}
df_test$map <- as.factor(df_test$map)
```

# La segunda línea convierte el factor a un número.
```{r}
df_test$map <- as.numeric(df_test$map)
```

```{r}
df_test$bomb_planted <- as.factor(df_test$bomb_planted)
df_test$bomb_planted <- as.numeric(df_test$bomb_planted)
```

```{r}
df_test$round_winner <- as.factor(df_test$round_winner)
df_test$round_winner <- as.numeric(df_test$round_winner)
df_test$round_winner <- df_test$round_winner - 1

```

```{r}
head(df_test)
```

```{r}
col <- colnames(df_test)
c <- lapply(col, function(i) cor(df_test$round_winner, df_test[,i]))
```

```{r}
str(df_test)
```
Hasta aquí hacemos transformaciones en los tipos, y convertimos clases categóricas en números discretos, como planted y winned a 0 si es negativo, 1 si es positivo.

-------------------------------------------------
Normalización de los datos usando Standard Scalar
-------------------------------------------------
crea el objeto standscl que se encarga de escalar los datos del dataframe df_test utilizando el metodo preProcess.
```{r}
standscl <- preProcess(df_test, method = c("center", "scale"))
```

La segunda línea se utiliza el objeto standscl para escalar los datos y se almacena en el mismo dataframe df_test.
La tercera línea convierte df_test a un dataframe de R.
```{r}
df_test <- predict(standscl, df_test)
df_test <- as.data.frame(df_test)
```

La quinta línea se asignan los nombres de las columnas del dataframe df_test a la variable col.
La sexta línea se codifica la variable round_winner utilizando la función as.factor() y as.numeric()
```{r}
colnames(df_test) <- col
df_test$round_winner <- as.factor(df_test$round_winner)
df_test$round_winner <- as.numeric(df_test$round_winner)
```

La séptima línea se utiliza la función head() para ver las primeras filas del dataframe.

Al final del proceso, se tiene un dataframe escalado y con la variable round_winner codificada.
```{r}
head(df_test)
```
```{r}
View(df_test)
```


--------------------------
Dividir los datos en X e Y
--------------------------

```{r}
x <- df_test[ , !(names(df_test) %in% c("round_winner"))]
head(x)
```

```{r}
y <- df_test$round_winner
y <- y-1
head(y)
```
Aquí hemos dividido los datos en las variables predictoras y la variable a predecir(y = round_winner)

----------------
Train Test Split
----------------

```{r}
split <- createDataPartition(y, p = 0.8, list = FALSE)
x_train <- x[split,]
y_train <- y[split]
x_test <- x[-split,]
y_test <- y[-split]
```

dividimos los datos en un train y test, otorgando a train el 80% de los datos, y en consecuencia un 20% a test.

# Apunte sobre el problema en cuestión
Es importante tener en cuenta que los datos de los que disponemos no nos van a permitir hacer predicciones si quiera cercanas al 90%, ya que, si prestamos atención al problema que estamos intentando resolver, una partida de counter strike en sí ya es bastante impredecible. Al final, se trata de 10 humanos con distinta skill(como puede ser la puntería), emociones, horas de sueño... 
Por ello, los resultados que se muestran a continuación son, al menos para los autores, bastante sorprendentes; ya que sólo conociendo factores como las armas, el dinero o la vida(sin saber quién hay detrás de la pantalla) se ha podido superar al azar por bastante.

# Modelo 1: Logistic Regression
```{r}
model_1 <- glm(y_train ~ ., data = x_train, family = binomial())
pred_1 <- predict(model_1, x_test, type = "response")
pred_1 <- ifelse(pred_1 > 0.5, 1, 0)
```

```{r}
pred_1 <- as.numeric(pred_1)
pred_1 <- as.factor(pred_1)
y_test <- as.numeric(y_test)
y_test <- as.factor(y_test)
```

```{r}
cr1 <- confusionMatrix(pred_1, y_test)
print(cr1)
```

```{r}
conf_matrix <- as.data.frame(table(pred_1, y_test))

ggplot(data = conf_matrix, aes(x = pred_1, y = y_test)) +
  ggtitle("Modelo 1: Logistic Regression", subtitle = "Confusion Matrix") +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15)) +
  xlab("Valores originales") + 
  ylab("Valores de test") +
  geom_tile(aes(fill = Freq)) +
  geom_text(aes(label = Freq), color = "black", size = 6, vjust = 0.1, hjust = 0.6) +
  scale_fill_gradient(low = "#E0CB48", high = "#CE93D8")
```

# Modelo 2: Decision Tree

```{r}
model_2 <- rpart(y_train ~ ., data = x_train, method = "class")
pred_2 <- predict(model_2, x_test, type = "class")
cr2 <- confusionMatrix(pred_2, y_test)
print(cr2)
```


```{r}
conf_matrix_2 <- as.data.frame(table(pred_2, y_test))

ggplot(data = conf_matrix_2, aes(x = pred_2, y = y_test)) +
  ggtitle("Modelo 2: Decision Tree", subtitle = "Confusion Matrix") +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15)) +
  xlab("Valores originales") + 
  ylab("Valores de test") +
  geom_tile(aes(fill = Freq)) +
  geom_text(aes(label = Freq), color = "black", size = 6, vjust = 0.1, hjust = 0.6) +
  scale_fill_gradient(low = "#86B1D3", high = "#F49541" )
```

```{r}
model_3 <- svm(y_train ~ ., data = x_train, type = "C-classification", kernel = "linear")
pred_3 <- predict(model_3, x_test, type = "class")
cr3 <- confusionMatrix(pred_3, y_test)
print(cr3)
```
```{r}
conf_matrix_3 <- as.data.frame(table(pred_3, y_test))

ggplot(data = conf_matrix_3, aes(x = pred_3, y = y_test)) +
  ggtitle("Modelo 3: SVM con Kernel Lineal", subtitle = "Confusion Matrix") +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) +
  theme(plot.title = element_text(size = 20), plot.subtitle = element_text(size = 15)) +
  xlab("Valores originales") + 
  ylab("Valores de test") +
  geom_tile(aes(fill = Freq)) +
  geom_text(aes(label = Freq), color = "black", size = 6, vjust = 0.1, hjust = 0.6) +
  scale_fill_gradient(low = "#86B1D3", high = "#F49541" )
```
```{r}
model_3 <- svm(y_train ~ ., data = x_train, type = "C-classification", kernel = "polynomial")
pred_3 <- predict(model_3, x_test, type = "class")
cr3 <- confusionMatrix(pred_3, y_test)
print(cr3)
```

```{r}
model_3 <- svm(y_train ~ ., data = x_train, type = "C-classification", kernel = "radial")
pred_3 <- predict(model_3, x_test, type = "class")
cr3 <- confusionMatrix(pred_3, y_test)
print(cr3)
```

```{r}
model_3 <- svm(y_train ~ ., data = x_train, type = "C-classification", kernel = "sigmoid")
pred_3 <- predict(model_3, x_test, type = "class")
cr3 <- confusionMatrix(pred_3, y_test)
print(cr3)
```





